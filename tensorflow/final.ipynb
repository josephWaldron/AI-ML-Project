{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:38:05.214406: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-18 01:38:05.214447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-18 01:38:05.215013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-18 01:38:05.218403: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 01:38:05.771766: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9430 validated image filenames belonging to 200 classes.\n",
      "Found 1179 validated image filenames belonging to 200 classes.\n",
      "Found 1179 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 64\n",
    "PATH = \"../data/CUB_200_2011\"\n",
    "labels = pd.read_csv(os.path.join(PATH, \"image_class_labels.txt\"), sep=\" \", header=None, names=[\"img_id\", \"label\"])\n",
    "images = pd.read_csv(os.path.join(PATH, \"images.txt\"), sep=\" \", header=None, names=[\"img_id\", \"filepath\"])\n",
    "classes = pd.read_csv(os.path.join(PATH, \"classes.txt\"), sep=\" \", header=None, names=[\"label\", \"category\"])\n",
    "num_classes = len(classes)\n",
    "df = pd.merge(images, labels, on=\"img_id\")\n",
    "df = pd.merge(df, classes, on=\"label\")\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "# Initialize transformations for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5], # Mimics ColorJitter's brightness adjustment\n",
    "    channel_shift_range=0.2, # Partially mimics ColorJitter's hue adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load the dataset and create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    directory=os.path.join(PATH, \"images\"),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"category\",\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5], # Mimics ColorJitter's brightness adjustment\n",
    "    channel_shift_range=0.2, # Partially mimics ColorJitter's hue adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    directory=os.path.join(PATH, \"images\"),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"category\",\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5], # Mimics ColorJitter's brightness adjustment\n",
    "    channel_shift_range=0.2, # Partially mimics ColorJitter's hue adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    directory=os.path.join(PATH, \"images\"),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"category\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:38:06.556420: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.569830: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.569893: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.571462: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.571504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.571543: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.769586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.769684: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.769693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 01:38:06.769741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-18 01:38:06.769761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7551 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:38:09.391943: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-18 01:38:11.569517: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f8dddba34b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-18 01:38:11.569548: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2023-12-18 01:38:11.573032: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702881491.634650   25140 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-18 01:38:25.426737: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-18 01:38:26.294272: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-18 01:38:27.568122: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-18 01:38:29.479569: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 110s 588ms/step - loss: 5.3498 - accuracy: 0.0031 - val_loss: 5.2980 - val_accuracy: 0.0051\n",
      "Epoch 2/200\n",
      "148/148 [==============================] - ETA: 0s - loss: 5.2990 - accuracy: 0.0031"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "num_epochs = 200\n",
    "leanring_rate = 0.0001\n",
    "\n",
    "vgg16Model = VGG16(weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(vgg16Model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=vgg16Model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=leanring_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "plot_accuracy_loss(history)\n",
    "\n",
    "model.save('../models/vgg16_EARLY.h5')\n",
    "model = tf.keras.models.load_model('../models/vgg16_EARLY.h5')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0001\n",
    "# Define the model\n",
    "learning_rate = 0.0001\n",
    "# Define the model\n",
    "resnetModel = ResNet50(weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(resnetModel.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=resnetModel.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "plot_accuracy_loss(history)\n",
    "\n",
    "model.save('../models/ResNet50_EARLY.h5')\n",
    "model = tf.keras.models.load_model('model_EARLY.h5')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "leanring_rate = 0.0001\n",
    "\n",
    "vgg16Model = VGG16(weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(vgg16Model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=vgg16Model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=leanring_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "plot_accuracy_loss(history)\n",
    "\n",
    "model.save('../models/vgg16.h5')\n",
    "model = tf.keras.models.load_model('../models/vgg16.h5')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.0001\n",
    "# Define the model\n",
    "resnetModel = ResNet50(weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(resnetModel.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=resnetModel.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "plot_accuracy_loss(history)\n",
    "\n",
    "model.save('../models/ResNet50.h5')\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inception with 229*299 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5], # Mimics ColorJitter's brightness adjustment\n",
    "    channel_shift_range=0.2, # Partially mimics ColorJitter's hue adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load the dataset and create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    directory=os.path.join(PATH, \"images\"),\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"category\",\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5], # Mimics ColorJitter's brightness adjustment\n",
    "    channel_shift_range=0.2, # Partially mimics ColorJitter's hue adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    directory=os.path.join(PATH, \"images\"),\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"category\",\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5], # Mimics ColorJitter's brightness adjustment\n",
    "    channel_shift_range=0.2, # Partially mimics ColorJitter's hue adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    directory=os.path.join(PATH, \"images\"),\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    dataframe=val_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"category\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0001\n",
    "# Define the model\n",
    "inceptionModel_EARLY = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(inceptionModel_EARLY.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=inceptionModel_EARLY.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=num_epochs,validation_data=val_generator)\n",
    "plot_accuracy_loss(history)\n",
    "model.save('../models/InceptionV3_EARLY.h5')\n",
    "\n",
    "model = tf.keras.models.load_model('../models/InceptionV3_EARLY.h5')\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "learning_rate = 0.0001\n",
    "# Define the model\n",
    "inceptionModel = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(inceptionModel.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=inceptionModel.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=num_epochs,validation_data=val_generator)\n",
    "plot_accuracy_loss(history)\n",
    "model.save('../models/InceptionV3.h5')\n",
    "\n",
    "model = tf.keras.models.load_model('../models/InceptionV3.h5')\n",
    "model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
